{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec648a3-b54d-4914-9667-a1fa4319b850",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting regionmask\n",
      "  Downloading regionmask-0.10.0-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: geopandas in /srv/conda/envs/notebook/lib/python3.10/site-packages (0.12.2)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from regionmask) (23.0)\n",
      "Requirement already satisfied: xarray>=0.15 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from regionmask) (2023.2.0)\n",
      "Requirement already satisfied: rasterio>=1.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from regionmask) (1.3.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from regionmask) (1.23.5)\n",
      "Requirement already satisfied: pooch>=1.2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from regionmask) (1.6.0)\n",
      "Requirement already satisfied: setuptools>=40.4 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from regionmask) (67.4.0)\n",
      "Requirement already satisfied: shapely>=1.7 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from regionmask) (1.8.5.post1)\n",
      "Requirement already satisfied: pyproj>=2.6.1.post1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from geopandas) (3.4.1)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from geopandas) (1.5.3)\n",
      "Requirement already satisfied: fiona>=1.8 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from geopandas) (1.9.1)\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (22.2.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
      "Requirement already satisfied: click~=8.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (8.1.3)\n",
      "Requirement already satisfied: munch>=2.3.2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
      "Requirement already satisfied: cligj>=0.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
      "Requirement already satisfied: certifi in /srv/conda/envs/notebook/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (2022.7.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pooch>=1.2->regionmask) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pooch>=1.2->regionmask) (2.28.2)\n",
      "Requirement already satisfied: affine in /srv/conda/envs/notebook/lib/python3.10/site-packages (from rasterio>=1.1->regionmask) (2.4.0)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from rasterio>=1.1->regionmask) (1.4.7)\n",
      "Requirement already satisfied: six in /srv/conda/envs/notebook/lib/python3.10/site-packages (from munch>=2.3.2->fiona>=1.8->geopandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.2->regionmask) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.2->regionmask) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.2->regionmask) (1.26.14)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio>=1.1->regionmask) (3.0.9)\n",
      "Installing collected packages: et-xmlfile, openpyxl, regionmask\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2 regionmask-0.10.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install regionmask geopandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8422a38b-1139-4765-ba05-40cde8e68a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importação das bibliotecas\n",
    "import gcsfs \n",
    "import intake\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import cftime\n",
    "import geopandas as gpd\n",
    "import regionmask\n",
    "import re\n",
    "import numpy as np\n",
    "import fiona\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a952daa-b158-4218-ac68-5a8da3d6ead6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_coords(ds):\n",
    "    \"\"\"Renomeia as variáveis de latitude, longitude e profundidade para 'lat', 'lon' e 'lev',\n",
    "    respectivamente, usando os nomes de variáveis de coordenadas encontrados automaticamente no arquivo.\n",
    "    \"\"\"\n",
    "    # Cria um dicionário com os possíveis nomes antigos das variáveis de latitude, longitude e profundidade\n",
    "    # e seus respectivos novos nomes\n",
    "    coord_names = {\n",
    "        'latitude': 'lat', 'nav_lat': 'lat', 'lat': 'lat',\n",
    "        'longitude': 'lon', 'nav_lon': 'lon', 'lon': 'lon',\n",
    "        'olevel': 'lev',\n",
    "        'olevel_bounds': 'lev_bnds'\n",
    "    }\n",
    "    # Itera sobre a lista de nomes de coordenadas presentes no arquivo\n",
    "    for coord_name in ds.coords.keys():\n",
    "        # Verifica se o nome da coordenada corresponde a um dos possíveis nomes antigos das variáveis de coordenadas\n",
    "        if coord_name in coord_names:\n",
    "            # Renomeia a variável de coordenada usando o método rename()\n",
    "            ds = ds.rename({coord_name: coord_names[coord_name]})\n",
    "    # Retorna o Dataset com as variáveis de coordenadas renomeadas\n",
    "    return ds.copy()\n",
    "\n",
    "#Função para acertar a variável tempo! Pois alguns formatos disponiveis no CMIP6 para a variável time dificultam sua manipulação. \n",
    "def to_360day_monthly(da):\n",
    "    ''' Conversão da dimensão de tempo de modelos climáticos.\n",
    "        Função criada por Claire Carouge no CLEX CMS Blog'''\n",
    "    val = da.copy()\n",
    "    time1 = da.time.copy()\n",
    "    for itime in range(val.sizes['time']):\n",
    "        bb = val.time.values[itime].timetuple()\n",
    "        time1.values[itime] = cftime.Datetime360Day(bb[0],bb[1],16)\n",
    "    val = val.assign_coords({'time':time1})\n",
    "    return val\n",
    "\n",
    "#Função que insere a varíavel área no meu xarray para cálculo de volume\n",
    "def assing_area(dic):\n",
    "    pesquisa = {'source_id': dic['source_id'],\n",
    "                'table_id': \"Ofx\",\n",
    "                'variable_id': 'areacello',\n",
    "                'experiment_id': dic['experiment_id'],\n",
    "                'member_id': dic['member_id']}\n",
    "    \n",
    "    cat_area = cmip6.search(require_all_on='source_id', **pesquisa)\n",
    "    cat_area = cat_area.to_dataset_dict(aggregate=True,\n",
    "                            storage_options={'token': 'anon'},\n",
    "                            xarray_open_kwargs={'consolidated': True,\n",
    "                            'decode_times': True,\n",
    "                            'use_cftime': True})\n",
    "    \n",
    "    #Caso não retorne nada retorna None\n",
    "    if len(cat_area)==0:\n",
    "        return None\n",
    "    \n",
    "    #Seleciona a áera do grid gn\n",
    "    for key in list(cat_area.keys()):\n",
    "        if \".gn\" in key:\n",
    "            ds_area = cat_area[key]\n",
    "        \n",
    "    ds_area = ds_area.squeeze().drop([\"member_id\", \"dcpp_init_year\"])\n",
    "    ds_select_area = ds_area[\"areacello\"]\n",
    "    return rename_coords(ds_select_area)\n",
    "\n",
    "#Função que converte a profundidade de centímetros para metro.\n",
    "def depth_m(ds):\n",
    "    if \"lev\" in ds:\n",
    "        if \"units\" in ds[\"lev\"].attrs:\n",
    "            units = ds[\"lev\"].units.lower()\n",
    "            if units == \"cm\" or units == \"centimeters\":\n",
    "                ds[\"lev\"] = ds[\"lev\"] / 100\n",
    "                ds[\"lev\"].attrs[\"units\"] = \"m\"\n",
    "    return ds\n",
    "\n",
    "#Renomeia a variável level_bnds\n",
    "def rename_lev_bnds(ds):\n",
    "    if 'axis_nbounds' in ds.dims:\n",
    "        ds = ds.rename_dims({'axis_nbounds': 'bnds'})\n",
    "    elif 'd2' in ds.dims:\n",
    "        ds = ds.rename_dims({'d2': 'bnds'})\n",
    "\n",
    "    return ds\n",
    "\n",
    "#Função para calcular a média de determinada variavel\n",
    "def media(ds, lev_1, lev_2): \n",
    "    ds = ds.sel(lev=slice(lev_1, lev_2))\n",
    "\n",
    "    # Crie uma máscara booleana para identificar onde a temperatura é não nula\n",
    "    temperature_not_null = ds['thetao'].notnull()\n",
    "\n",
    "    # Aplique a máscara à variável de volume para obter um volume ponderado válido\n",
    "    weighted_volume = ds['vol'] * temperature_not_null\n",
    "\n",
    "    # Calcule as médias ponderadas para temperatura e salinidade em relação ao volume válido\n",
    "    media_thetao = ((ds['thetao'] * ds['vol']).sum() /  weighted_volume.sum()).compute()\n",
    "\n",
    "    # Crie uma máscara booleana para identificar onde a temperatura é não nula\n",
    "    so_not_null = ds['so'].notnull()\n",
    "\n",
    "    # Aplique a máscara à variável de volume para obter um volume ponderado válido\n",
    "    weighted_volume = ds['vol'] * so_not_null\n",
    "\n",
    "    # Calcule as médias ponderadas para temperatura e salinidade em relação ao volume válido\n",
    "    media_so = ((ds['so'] * ds['vol']).sum() /  weighted_volume.sum()).compute()\n",
    "    \n",
    "    return media_thetao, media_so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "680ae250-4828-442d-883c-3247df398f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Acessa o conjunto de metadados do CMIP6 hospedados no Google Cloud.\n",
    "cmip6 = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcdea2a4-cc3d-49b5-a66b-378bf60a0075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Lendo a minha Tabela de Modelo.\n",
    "#Verifique o caminho, no meu jupyter lab está tudo na mesma pasta.\n",
    "df = pd.read_excel(\"Tabela_Modelos/Tabela_Modelos.xlsx\", sheet_name = 1)\n",
    "df = df.rename(columns = lambda x : x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "085eff99-f207-4bdb-bd92-5978e144c24e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Realiza minha pesquisa de acordo com a minha Tabela de Modelos\n",
    "pesquisas = []\n",
    "for index, row in df.iterrows():\n",
    "    pesquisa = {'source_id': row['source_id'],\n",
    "                'table_id': row['table_id'],\n",
    "                'variable_id': row['variable_id'].split(', '),\n",
    "                'experiment_id': row['experiment_id'],\n",
    "                'member_id': row['member_id']}\n",
    "    pesquisas.append(pesquisa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a70e4233-9d71-4da3-aec6-dd5ed7a83580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('Area_Projeto/50S_20S/50S_20S.kml', driver=\"KML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e08759e-18f0-4302-b1cb-3ecf1261c4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/intake_esm/_search.py:80: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for _, group in grouped:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/intake_esm/core.py:645\u001b[0m, in \u001b[0;36mesm_datastore.to_dataset_dict\u001b[0;34m(self, xarray_open_kwargs, xarray_combine_by_coords_kwargs, preprocess, storage_options, progressbar, aggregate, skip_on_error, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m     gen \u001b[38;5;241m=\u001b[39m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(future_tasks)\n\u001b[0;32m--> 645\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m gen:\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/fastprogress/fastprogress.py:41\u001b[0m, in \u001b[0;36mProgressBar.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen):\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal: \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/concurrent/futures/_base.py:245\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    243\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 245\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pesquisa \u001b[38;5;129;01min\u001b[39;00m pesquisas:\n\u001b[1;32m     13\u001b[0m     cat \u001b[38;5;241m=\u001b[39m cmip6\u001b[38;5;241m.\u001b[39msearch(require_all_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpesquisa)\n\u001b[0;32m---> 14\u001b[0m     cat \u001b[38;5;241m=\u001b[39m \u001b[43mcat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataset_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggregate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mxarray_open_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconsolidated\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdecode_times\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_cftime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(cat\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.gn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/intake_esm/core.py:635\u001b[0m, in \u001b[0;36mesm_datastore.to_dataset_dict\u001b[0;34m(self, xarray_open_kwargs, xarray_combine_by_coords_kwargs, preprocess, storage_options, progressbar, aggregate, skip_on_error, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m sources \u001b[38;5;241m=\u001b[39m {key: source(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msource_kwargs) \u001b[38;5;28;01mfor\u001b[39;00m key, source \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    634\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 635\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mdask\u001b[38;5;241m.\u001b[39msystem\u001b[38;5;241m.\u001b[39mCPU_COUNT) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    636\u001b[0m     future_tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    637\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(_load_source, key, source) \u001b[38;5;28;01mfor\u001b[39;00m key, source \u001b[38;5;129;01min\u001b[39;00m sources\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    638\u001b[0m     ]\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogressbar:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define o slice de tempo inicial\n",
    "time_inicio = 1970\n",
    "time_fim = 1980\n",
    "\n",
    "# Realiza um for para selecionar minha área de interesse para todos os Modelos\n",
    "for pesquisa in pesquisas:\n",
    "    cat = cmip6.search(require_all_on='source_id', **pesquisa)\n",
    "    cat = cat.to_dataset_dict(aggregate=True,\n",
    "                            storage_options={'token': 'anon'},\n",
    "                            xarray_open_kwargs={'consolidated': True,\n",
    "                            'decode_times': True,\n",
    "                            'use_cftime': True})\n",
    "    \n",
    "    for key in list(cat.keys()):\n",
    "        if \".gn\" in key:\n",
    "            ds = cat[key]\n",
    "            \n",
    "            #Area do modelo.\n",
    "            ds_area = assing_area(pesquisa)\n",
    "\n",
    "            if ds_area is None:\n",
    "                continue\n",
    "\n",
    "            #Corrigindo os times. Utiliza a função definida anteriormente para correção da variável time\n",
    "            ds = to_360day_monthly(ds)\n",
    "\n",
    "            #Renomeia as variaves para uniformizar o nome nos modelos\n",
    "            ds = rename_coords(ds)\n",
    "\n",
    "            #Renomeia o lev_bnds\n",
    "            ds = rename_lev_bnds(ds)\n",
    "\n",
    "            #Trasnforma as unidades da profundidade para metros\n",
    "            ds = depth_m(ds)\n",
    "\n",
    "            #Deleta as variáveis presentes no xarray que não são do nosso interesse.\n",
    "            ds_drop = ds.drop([v for v in ds.coords if v not in ['lat', 'lon', 'time', 'lev', 'lev_bnds']])\n",
    "\n",
    "            #Adiciona a variável área ao meu xarray\n",
    "            ds_with_area = ds_drop.assign_coords(area=ds_area)\n",
    "\n",
    "            #Define um slice do time\n",
    "            ds_time = ds_with_area.sel(time=slice(str(time_inicio), str(time_fim)))\n",
    "\n",
    "            #Faz o squeeze para tirar dimensões não importantes\n",
    "            ds_time = ds_time.squeeze()\n",
    "\n",
    "            #Converte o GeoDataFrame para um objeto region mask\n",
    "            mask = regionmask.mask_geopandas(gdf, ds_time['lon'], ds_time['lat'])\n",
    "\n",
    "            #Aplica a máscara ao dataset\n",
    "            ds_masked = ds_time.where(mask==mask, drop=True)\n",
    "            \n",
    "            #Calcula a espessura\n",
    "            espessura = ds_masked.lev_bnds.diff(dim='bnds').squeeze()\n",
    "    \n",
    "            #Coloca a variável espessura dentro do xarray\n",
    "            ds_lev = ds_masked.assign(espessura=espessura)\n",
    "\n",
    "            #Calcula o volume \n",
    "            ds_lev[\"vol\"] = ds_lev[\"espessura\"] * ds_lev[\"area\"]\n",
    "            \n",
    "            results = []\n",
    "            \n",
    "            for i in ds_lev.time:\n",
    "                \n",
    "                ds_t = ds_lev.sel(time=i)\n",
    "                \n",
    "                mean_t, mean_s = media(ds_t, 500, 2000)\n",
    "\n",
    "                results.append({\n",
    "                    'time': i.values,\n",
    "                    'media_thetao': mean_t.values,\n",
    "                    'media_so': mean_s.values\n",
    "                })\n",
    "\n",
    "            # Crie um DataFrame a partir dos resultados\n",
    "            result_df = pd.DataFrame(results)\n",
    "            \n",
    "            nome = key.split('.')\n",
    "            \n",
    "            chave = '.'.join(nome[0:4])\n",
    "            \n",
    "            result_df.to_csv(\"Medias_Temporais/50S_20S/500_2000m/{}.csv\".format(chave))\n",
    "            \n",
    "            print(\"Processamento Concluído para o dataframe {}\".format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b081f-3816-4ca2-bd59-2f2cc0b1d1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
